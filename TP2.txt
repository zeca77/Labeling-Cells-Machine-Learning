Attention:
- Do not edit this file in text editors like Word. Use a plain text editor only. In case of doubt, you can use Spyder as a text editor.
- Do not change the structure of this file. Just fill in your answers in the places provided (After the R#: tag).
- You can add lines in the spaces for your answers but your answers should be brief and straight to the point.
- You can include references to images or html files such as the reports generated with clusters. To do this, simply include this document in the folder with the reports or images and refer them in the text by the file name in an isolated line. For example, the line

test.png

refers to a test.png image file in the same folder as this document.

QUESTIONS:


Q1: After extracting the attributes, did you standardize or normalize the values? Justify your decision.
R1:Yes, the attributes where normalized, since we did not know the distribution of the data. 

Q2: Explain how you found the parameters for the clustering algorithms.
R2: For each of the algorithms, we found which number of parameters corresponded to the highest adjusted random score value, because this value takes into account that there will be an inbalance in how the clusters will be classified.

Q3: Describe your analysis of the parameters using the internal and external indicators referred in the assignment page. Include the  plots for the indicator values ​​(indicating the image name of each plot in one line in your answer) as a function of the parameters and explain how you chose the ranges for examining these parameters. Indicate, with justification, what conclusions you can draw from this analysis.
R3: In the pictures folder, there is a graph for each one of the three models. For each one of the models, we can see that each one of the parameters gets worse as we increase the number of clusters. 
The graphs aglomerative_clustering.png , k_means.png and spectral_clustering.png represent those plots.
This is expected, since there is a higher chance of hitting clusters that we are not supposed to classify. 
When it comes to the number of clusters, we used the number 18 as an example number for the maximum number of clusters,but this value could be lower, because we can already see a decay after 10 clusters. 
When it comes to the number of neighbourhood values, we used the intervale between 0 and 200 , although none of the values really changed, or made any kind of progression.


Q4: Select some of the parameter values ​​tested in the question above and examine the corresponding clusters more closely, generating the HTML file with the images. Explain how you selected these parameter values, discuss the different options and propose a recommendation that could help the biologists' task of classifying cells and rejecting segmentation errors.
R4: For the aglomerative clustering, we chose 4 clusters, because it is the point wiht the highest precision and recall, while remaining with a high value of purity.
For the k-means we chose 3 clusters, because from then on precision and recall spike down.
And finally, for the spectral, we used 10 as the neighbourhood value, but as the graph called spectral_clustering_neighbourhoods.png shows, there were no differences noticed. As for the clusters, we also used 3 because it's the value where the random index, and the other variables peak.
When it comes to the analysis, we can tell that in the aglomerative clustering, it has somewhat of an ability to group ells of the 3rd phase together, aswell as grouping the clearer cells of the group 1 together.It also seemed to group cells with weird shapes together.
The k-means algorithm clustered cells of what we know the group 1 is very well, but it failed to differentiate between the two other classes.
The spectral algorithm performed somewhat similarly when it comes to classifiying cells of the first group together, although it did not tell a clear difference between the rest.
The main sugestion when it comes to the scientists is to increase the size of the classified dataset, since that can really help when it comes to chosing the better model.

Q5: Discuss advantages or problems with the algorithms analysed for the purpose of helping biologists to organize these images, considering your theoretical knowledge of these algorithms as well as the results you obtained in your work.
R5: The main issue with these algorithms, would be the fact that they are all unsupervised algorithms, so that means that they do not take into account the fact that some of the data is classified when they fit the model to the data.


Q6: Consider other clustering algorithms embedded in the Scikit-Learn library. Choose one and apply it to this problem, optimizing the parameters you deem appropriate in the way that you find adequate. Justify your choices and discuss whether this option would yield more useful results for biologists.
R6:The algorithm chosen was affinity propagation. The parameter optimized was damping. This algorithm would not be very helpful since it resulted in a very high number of clusters,that might not be too correlated with each other. However, with some improvements, like for example grouping some of the clusters together, it might be improved.


(Optional) Q7: Explain how you selected the best attributes for the clustering phase. In particular, indicate the visualization methods used to explore the extracted attributes and any statistical tests used.
R7:


(Optional) Q8: Implement the Bissecting K-Means hierarchical clustering algorithm as described in the assignment page and Lecture 19. Examine and discuss the results and their application to the problem of helping the biologists select and classify cell images.
R8:

